{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial and cookbook\n",
    "\n",
    "By [Allison Parrish](http://www.decontextualize.com/)\n",
    "\n",
    "Draft version!\n",
    "\n",
    "This notebook shows you how to use [Pincelate](https://pincelate.readthedocs.io/) and how to do some interesting things with it.\n",
    "\n",
    "Pincelate is a Python library that provides a simple interface for a machine learning model that can sound out English words and spell English words based on how they sound. \"Sounding out\" here means converting letters (\"orthography\") to sounds (\"phonemes\"), and \"spelling\" means converting sounds to letters (phonemes to orthography). The model is trained on the [CMU Pronouncing Dictionary](http://www.speech.cs.cmu.edu/cgi-bin/cmudict), which means it generally sounds words out as though speaking \"standard\" North American English, and spells words according to \"standard\" North American English rules (at least as far as the model itself is accurate).\n",
    "\n",
    "## Preliminaries\n",
    "\n",
    "Loading various required modules, plus the language model and Pincelate. To run these experiments, you'll need to install Pincelate. Type the following at a command prompt:\n",
    "\n",
    "    pip install tensorflow  # or tensorflow-gpu\n",
    "    pip install pincelate\n",
    "    \n",
    "(Installing Pincelate will also install Pronouncing, which we'll use at various points in the experiments below.)\n",
    "\n",
    "Other libraries you'll need for this notebook: `numpy` and `scipy`. If you're using Anaconda, you already have these libraries. If not, install them like so:\n",
    "\n",
    "    pip install numpy scipy\n",
    "    \n",
    "Importing numpy and Pronouncing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pronouncing as pr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now import Pincelate and instantiate a Pincelate object. (This will load the pre-trained model provided with the package.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from pincelate import Pincelate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pin = Pincelate()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Later in the notebook, I'm going to use some of Jupyter Notebook's interactive features, so I'll import the libraries here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive_output, Layout, HBox, VBox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sounding out and spelling\n",
    "\n",
    "The CMU Pronouncing Dictionary provides a database of tens of thousands of English words along with their pronunciations. I made a Python library called [Pronouncing](https://github.com/aparrish/pronouncingpy) to make it easier to look up words in dictionary. Here's how it works. To get the pronunciation of a word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'AE1 L F AH0 B EH2 T'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.phones_for_word(\"alphabet\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CMU Pronouncing Dictionary provides pronunciations as a list of phonemes in a phonetic transcription scheme called [Arpabet](https://en.wikipedia.org/wiki/ARPABET), in which each unique sound in English is given a different symbol.\n",
    "\n",
    "If you want to find words that have a particular pronunciation, you can look them up in the CMU Pronouncing Dictionary like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['flour', 'flower']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.search(\"^F L AW1 ER0$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That all seems pretty straightforward! The problem arises when you want to spell a word that *isn't* in the CMU Pronouncing Dictionary. You'll get an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-4aa47dd2de94>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mphones_for_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mimsy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "pr.phones_for_word(\"mimsy\")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Likewise, if you've just invented a new word and have a pronunciation in mind, the CMU Pronouncing Dictionary won't be able to help you spell it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pr.search(\"^B L AH1 R F$\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where Pincelate comes in handy. Pincelate's machine learning model can provide phonemes for words that aren't in the CMU Pronouncing Dictionary, and produce plausible spellings of arbitrary sequences of phonemes. To sound out a word, use the `.soundout()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['M', 'IH1', 'N', 'S', 'IY0']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pin.soundout(\"mimsy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... and to produce a plausible spelling for a word whose sounds you just made up, use the `.spell()` method, passing it a list of Arpabet phonemes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'blear'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pin.spell(['B', 'L', 'AH1', 'R', 'F'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's important to note that Pincelate's `.soundout()` method will *only* work with letters that appear the CMU Pronouncing Dictionary's vocabulary. (You need to use lowercase letters only.) So the following will throw an error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'é'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-0edf2522d617>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"étui\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/pincelate/pincelate/__init__.py\u001b[0m in \u001b[0;36mspell\u001b[0;34m(self, phones, temperature)\u001b[0m\n\u001b[1;32m    130\u001b[0m                 \u001b[0mthis_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphone_feature_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m                 \u001b[0mthis_feat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mphone_feature_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0mfeats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mthis_feat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m         state_val = self.phon2orth.infer(\n",
      "\u001b[0;31mKeyError\u001b[0m: 'é'"
     ]
    }
   ],
   "source": [
    "pin.spell(\"étui\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: phoneme frequency analysis\n",
    "\n",
    "Using Pincelate's model, we can do phonetic analysis on texts, even texts that contain words that aren't in the CMU Pronouncing Dictionary. For example, let's find out what the most common phonemes are in Lewis Carroll's \"Jabberwocky.\" Here's the full text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "'Twas brillig, and the slithy toves\n",
    "      Did gyre and gimble in the wabe:\n",
    "All mimsy were the borogoves,\n",
    "      And the mome raths outgrabe.\n",
    "\n",
    "\"Beware the Jabberwock, my son!\n",
    "      The jaws that bite, the claws that catch!\n",
    "Beware the Jubjub bird, and shun\n",
    "      The frumious Bandersnatch!\"\n",
    "\n",
    "He took his vorpal sword in hand;\n",
    "      Long time the manxome foe he sought---\n",
    "So rested he by the Tumtum tree\n",
    "      And stood awhile in thought.\n",
    "\n",
    "And, as in uffish thought he stood,\n",
    "      The Jabberwock, with eyes of flame,\n",
    "Came whiffling through the tulgey wood,\n",
    "      And burbled as it came!\n",
    "\n",
    "One, two! One, two! And through and through\n",
    "      The vorpal blade went snicker-snack!\n",
    "He left it dead, and with its head\n",
    "      He went galumphing back.\n",
    "\n",
    "\"And hast thou slain the Jabberwock?\n",
    "      Come to my arms, my beamish boy!\n",
    "O frabjous day! Callooh! Callay!\"\n",
    "      He chortled in his joy.\n",
    "\n",
    "'Twas brillig, and the slithy toves\n",
    "      Did gyre and gimble in the wabe:\n",
    "All mimsy were the borogoves,\n",
    "      And the mome raths outgrabe.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, parse the text into words and convert them to lower case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "words = [item.lower() for item in re.findall(r\"\\b(\\w+)\\b\", text)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a random sample of the words just to ensure that we've got what we wanted:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'and',\n",
       " 'so',\n",
       " 'frumious',\n",
       " 'thou',\n",
       " 'awhile',\n",
       " 'o',\n",
       " 'tumtum',\n",
       " 'one',\n",
       " 'wabe']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "random.sample(words, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we'll use `.soundout()` to get a list of phonemes for each item, and feed them to a `Counter()` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "phoneme_count = Counter()\n",
    "for word in words:\n",
    "    phoneme_count.update(pin.soundout(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now print out the most common phonemes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('N', 51),\n",
       " ('IH1', 43),\n",
       " ('T', 36),\n",
       " ('S', 36),\n",
       " ('AE1', 36),\n",
       " ('R', 34),\n",
       " ('D', 32),\n",
       " ('TH', 27),\n",
       " ('EH1', 27),\n",
       " ('L', 24),\n",
       " ('B', 18),\n",
       " ('M', 17)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phoneme_count.most_common(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For reference, the following cell calculates the most common phonemes in all of the CMU Pronouncing Dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('AH0', 63133),\n",
       " ('N', 61234),\n",
       " ('S', 50432),\n",
       " ('L', 49963),\n",
       " ('T', 49074),\n",
       " ('R', 46468),\n",
       " ('K', 43077),\n",
       " ('D', 32558),\n",
       " ('IH0', 30198),\n",
       " ('M', 29741),\n",
       " ('Z', 28217),\n",
       " ('ER0', 23954)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmu_phoneme_count = Counter()\n",
    "for word, phones in pr.pronunciations:\n",
    "    cmu_phoneme_count.update(phones.split())\n",
    "cmu_phoneme_count.most_common(12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could do a more formal analysis and make claims about how Lewis Carroll's *Jabberwocky* differs significantly from typical English from a phonetic standpoint, but just from a quick look we can see that \"Jabberwocky\" is heavy on the `AE1`s (i.e., the vowel sound in \"hand\") and `B`s."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Spelling words from random phonemes\n",
    "\n",
    "Having just counted up all of the phonemes in the CMU Pronouncing Dictionary, we can now invent somewhat plausible neologisms by drawing phonemes at random according to their frequency and gluing them together. (\"Neologism\" is a fancy word for \"made-up word.\") The following code normalizes the phoneme frequencies so we can use them in numpy's `np.random.choice` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_phonemes = list(cmu_phoneme_count.keys())\n",
    "phoneme_frequencies = np.array(list(cmu_phoneme_count.values()), dtype=np.float32)\n",
    "phoneme_frequencies /= phoneme_frequencies.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And then this function will return a random neologism, created from phonemes drawn at random based on their frequency in English words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neologism_phonemes():\n",
    "    return [np.random.choice(all_phonemes, p=phoneme_frequencies)\n",
    "            for item in range(random.randrange(3,10))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a handful, just to get a taste:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['T', 'IH1', 'L', 'N', 'T', 'N', 'N', 'T', 'ER0']\n",
      "['AA1', 'V', 'OW1', 'AH0']\n",
      "['AW1', 'G', 'G', 'ER1']\n",
      "['AE2', 'N', 'K']\n",
      "['EH1', 'B', 'L', 'L', 'IH0']\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(neologism_phonemes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's all well and good! Try sounding out some of these on your own (consult the [Arpabet](https://en.wikipedia.org/wiki/ARPABET) table to find the English sound corresponding to each symbol).\n",
    "\n",
    "But how do you *spell* these neologisms? Why, with Pincelate's `.spell()` method of course:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'richale'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pin.spell(neologism_phonemes())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here's a for loop that generates neologisms and prints them along with their spellings:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "roughler ['R', 'AH0', 'ER0', 'L', 'R', 'L', 'V', 'ER1']\n",
      "earole ['IH2', 'R', 'L', 'OW1', 'T']\n",
      "eaist ['IY2', 'IY0', 'HH', 'D', 'D']\n",
      "aibes ['AE1', 'IH0', 'B', 'S']\n",
      "iessier ['IY0', 'IY0', 'S', 'IY2', 'ER0']\n",
      "stemen ['S', 'T', 'EH1', 'M', 'T', 'S', 'N']\n",
      "chonce ['K', 'N', 'AA1', 'K', 'K', 'AH0', 'R', 'S']\n",
      "nlucke ['N', 'L', 'T', 'AH1', 'K']\n",
      "mitson ['M', 'T', 'IH1', 'D', 'S', 'IH1', 'K', 'N']\n",
      "erte ['ER0', 'T', 'R']\n",
      "briche ['B', 'K', 'G', 'HH', 'ER1', 'IH1']\n",
      "ailear ['EY1', 'L', 'EY1', 'B']\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    phonemes = neologism_phonemes()\n",
    "    print(pin.spell(phonemes), phonemes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phoneme features\n",
    "\n",
    "The examples above use the phoneme as the basic unit of English phonetics. But each phoneme itself has characteristics, and many phonemes have characteristics in common. For example, the phoneme `/B/` has the following characteristics:\n",
    "\n",
    "* *bilabial*: you put your lips together when you say it\n",
    "* *stop*: airflow from the lungs is completely obstructed\n",
    "* *voiced*: your vocal cords are vibrating while you say it\n",
    "\n",
    "The phoneme `/P/` shares two out of three of these characteristics (it's *bilabial* and a *stop*, but is not voiced). The phoneme `/AE/`, on the other hand, shares *none* of these characteristics. Instead, it has these characteristics:\n",
    "\n",
    "* *vowel*: your mouth doesn't stop or occlude airflow when making this sound\n",
    "* *low*: your tongue is low in the mouth\n",
    "* *front*: your tongue is advanced forward in the mouth\n",
    "* *unrounded*: your lips are not rounded\n",
    "\n",
    "These characteristics of phonemes are traditionally called \"features.\" You can look up the features for particular phonemes using the `phone_feature_map` variable in Pincelate's `featurephone` module:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pincelate.featurephone import phone_feature_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, to get the features for the vowel `/UW/` (vowel sound in \"toot\"):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('hgh', 'bck', 'rnd', 'vwl')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phone_feature_map['UW']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The features are referred to here with short three-letter abbreviations. Here's a full list:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `alv`: alveolar\n",
    "* `apr`: approximant\n",
    "* `bck`: back\n",
    "* `blb`: bilabial\n",
    "* `cnt`: central\n",
    "* `dnt`: dental\n",
    "* `fnt`: front\n",
    "* `frc`: fricative\n",
    "* `glt`: glottal\n",
    "* `hgh`: high\n",
    "* `lat`: lateral\n",
    "* `lbd`: labiodental\n",
    "* `lbv`: labiovelar\n",
    "* `lmd`: low-mid\n",
    "* `low`: low\n",
    "* `mid`: mid\n",
    "* `nas`: nasal\n",
    "* `pal`: palatal\n",
    "* `pla`: palato-alveolar\n",
    "* `rnd`: rounded\n",
    "* `rzd`: rhoticized\n",
    "* `smh`: semi-high\n",
    "* `stp`: stop\n",
    "* `umd`: upper-mid\n",
    "* `unr`: unrounded\n",
    "* `vcd`: voiced\n",
    "* `vel`: velar\n",
    "* `vls`: voiceless\n",
    "* `vwl`: vowel\n",
    "\n",
    "Additionally, there are two special phoneme features:\n",
    "\n",
    "* `beg`: beginning of word\n",
    "* `end`: end of word\n",
    "\n",
    "... which are found and the beginnings and endings of words."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Internally, Pincelate's model operates on these *phoneme features*, instead of directly on whole phonemes. This allows the model to capture and predict underlying similarities between phonemes.\n",
    "\n",
    "Pincelate's `.phonemefeatures()` method works a lot like `.spell()`, except instead of returning a list of phonemes, it returns a [numpy](https://numpy.org/) array of *phoneme feature probabilities*. This array has one row for each predicted phoneme, and one column for the probability (between 0 and 1) of a phoneme feature being a component of each phoneme. To illustrate, here I get the feature array for the word `cat`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_feats = pin.phonemefeatures(\"cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This array has the following shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 32)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which tells us that there are five predicted phonemes. (The `32` is the total number of possible features.) The word `cat`, of course, has only three phonemes (`/K AE T/`)—the extra two are the special \"beginning of the word\" and \"end of the word\" phonemes at the beginning and end, respectively.\n",
    "\n",
    "### Examining predicted phoneme features\n",
    "\n",
    "Let's look at the feature probabilities for the first phoneme (after the special \"beginning of the word\" token at index 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([4.47422266e-04, 1.18613243e-05, 4.32133675e-06, 0.00000000e+00,\n",
       "       4.28557396e-05, 1.25169754e-06, 0.00000000e+00, 2.98023224e-08,\n",
       "       9.17911530e-06, 2.17527151e-04, 4.31716442e-04, 2.38418579e-07,\n",
       "       0.00000000e+00, 6.36577606e-05, 2.98023224e-08, 2.05636024e-06,\n",
       "       2.62558460e-05, 1.49011612e-07, 3.12924385e-06, 7.15255737e-07,\n",
       "       1.17987394e-04, 2.08616257e-07, 0.00000000e+00, 4.08291817e-06,\n",
       "       9.99740005e-01, 1.83761120e-04, 3.27825546e-07, 4.73856926e-06,\n",
       "       1.52707100e-04, 9.99939680e-01, 9.99865890e-01, 9.04798508e-05])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feats[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can look up the index in this array associated with a particular phoneme feature using Pincelate's `.featureidx()` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9999396800994873"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cat_feats[1][pin.featureidx('vel')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that the `vel` (velar) feature for this phoneme is predicted with almost 100% probability—which makes sense, since the phoneme we'd anticipate—`/K/` is a voiceless velar stop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following bit of code steps through each row in this array and prints out the phoneme features with the highest probability in that row, using numpy's `argsort` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "phoneme 0\n",
      "beg 1.0\n",
      "vwl 0.0\n",
      "vls 0.0\n",
      "apr 0.0\n",
      "bck 0.0\n",
      "\n",
      "phoneme 1\n",
      "vel 0.9999396800994873\n",
      "vls 0.9998658895492554\n",
      "stp 0.9997400045394897\n",
      "alv 0.0004474222660064697\n",
      "glt 0.0004317164421081543\n",
      "\n",
      "phoneme 2\n",
      "vwl 0.9994708895683289\n",
      "unr 0.9978153109550476\n",
      "str 0.9701219201087952\n",
      "low 0.9265567064285278\n",
      "fnt 0.8983818888664246\n",
      "\n",
      "phoneme 3\n",
      "alv 0.9887728095054626\n",
      "vls 0.9821089506149292\n",
      "stp 0.9477603435516357\n",
      "frc 0.11646848917007446\n",
      "vcd 0.0205477774143219\n",
      "\n",
      "phoneme 4\n",
      "end 0.9521546363830566\n",
      "vwl 0.23826062679290771\n",
      "unr 0.17280638217926025\n",
      "cnt 0.07723551988601685\n",
      "fnt 0.059767305850982666\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def idxfeature(pin, idx):\n",
    "    return pin.orth2phon.target_vocab[idx]\n",
    "for i, phon in enumerate(cat_feats):\n",
    "    print(\"phoneme\", i)\n",
    "    for idx in np.argsort(phon)[::-1][:5]:\n",
    "        print(idxfeature(pin, idx), phon[idx])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Distinctive phoneme features in lines of poetry\n",
    "\n",
    "Poems are often organized into lines. In the following example, I look at our example poem (\"Jabberwocky\", included this notebook above) and try to figure out what makes each line of the poem *phonetically distinct* from the other lines.\n",
    "\n",
    "To do this, we need a baseline of phoneme feature frequency in the entire text. As a measure of this, I'm just going to calculate phoneme feature probabilities for every word in the poem (using the `words` list defined above), add them up, and normalize by the number of words in the poem. The code in the following cell uses `.phonemefeatures()` for each word and then numpy's `concatenate()` function to stack them into one big array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_feats = np.concatenate([pin.phonemefeatures(word) for word in words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(912, 32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_feats.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we normalize by the length of the array:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_feats_normal = word_feats.sum(axis=0) / word_feats.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell prints out the top ten phoneme features in the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alv 0.2615780602617745\n",
      "vwl 0.24332700839690996\n",
      "unr 0.20295134529863534\n",
      "beg 0.18311407528164095\n",
      "str 0.17805135380803494\n",
      "end 0.14587022873916125\n",
      "fnt 0.14156226241928443\n",
      "vls 0.14133350243955328\n",
      "stp 0.13737183743924425\n",
      "frc 0.10895491590756073\n"
     ]
    }
   ],
   "source": [
    "for idx in np.argsort(word_feats_normal)[::-1][:10]:\n",
    "    print(idxfeature(pin, idx), word_feats_normal[idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So: lots of vowels, mainly unrounded and front; lots of alveolar stops, more voiced than voiceless. If you were to mimic the sound of this text, in other words, you might say something like \"dee dee dat dittee tee day...\"\n",
    "\n",
    "The following cell compares the phoneme feature probabilities in *each line* of the poem to the phoneme feature probabilities of a poem as a whole, and then prints out the top five phoneme features for each line that occur with higher frequency than they do on average in the entire poem. (This is a complicated bit of code, so I included some comments in-line.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Twas brillig, and the slithy toves\n",
      "alv: +0.054, frc: +0.035, vls: +0.022, vcd: +0.020, lbd: +0.015\n",
      "\n",
      "Did gyre and gimble in the wabe:\n",
      "vcd: +0.093, stp: +0.050, fnt: +0.043, smh: +0.040, unr: +0.029\n",
      "\n",
      "All mimsy were the borogoves,\n",
      "vwl: +0.043, lmd: +0.042, blb: +0.035, lat: +0.030, unr: +0.023\n",
      "\n",
      "And the mome raths outgrabe.\n",
      "nas: +0.039, low: +0.038, rnd: +0.031, bck: +0.027, umd: +0.015\n",
      "\n",
      "\"Beware the Jabberwock, my son!\n",
      "blb: +0.047, nas: +0.021, frc: +0.015, low: +0.011, dnt: +0.004\n",
      "\n",
      "The jaws that bite, the claws that catch!\n",
      "vls: +0.125, frc: +0.080, dnt: +0.069, stp: +0.061, low: +0.035\n",
      "\n",
      "Beware the Jubjub bird, and shun\n",
      "vcd: +0.070, cnt: +0.050, stp: +0.045, mid: +0.043, blb: +0.037\n",
      "\n",
      "The frumious Bandersnatch!\"\n",
      "frc: +0.058, vls: +0.041, lbd: +0.038, alv: +0.022, hgh: +0.021\n",
      "\n",
      "He took his vorpal sword in hand;\n",
      "apr: +0.070, glt: +0.060, end: +0.029, bck: +0.020, rnd: +0.020\n",
      "\n",
      "Long time the manxome foe he sought---\n",
      "nas: +0.049, rnd: +0.042, bck: +0.038, vls: +0.031, blb: +0.022\n",
      "\n",
      "So rested he by the Tumtum tree\n",
      "alv: +0.058, vls: +0.045, apr: +0.023, mid: +0.023, cnt: +0.017\n",
      "\n",
      "And stood awhile in thought.\n",
      "alv: +0.054, end: +0.031, rnd: +0.027, bck: +0.026, nas: +0.018\n",
      "\n",
      "And, as in uffish thought he stood,\n",
      "end: +0.048, vls: +0.031, frc: +0.024, mid: +0.020, cnt: +0.020\n",
      "\n",
      "The Jabberwock, with eyes of flame,\n",
      "frc: +0.069, lbd: +0.051, vls: +0.032, fnt: +0.021, smh: +0.019\n",
      "\n",
      "Came whiffling through the tulgey wood,\n",
      "lbv: +0.029, apr: +0.029, vls: +0.025, dnt: +0.023, vel: +0.018\n",
      "\n",
      "And burbled as it came!\n",
      "stp: +0.056, cnt: +0.046, blb: +0.036, low: +0.036, rzd: +0.033\n",
      "\n",
      "One, two! One, two! And through and through\n",
      "bck: +0.067, alv: +0.053, rnd: +0.041, apr: +0.037, umd: +0.034\n",
      "\n",
      "The vorpal blade went snicker-snack!\n",
      "vls: +0.062, lmd: +0.041, alv: +0.040, lat: +0.030, stp: +0.024\n",
      "\n",
      "He left it dead, and with its head\n",
      "fnt: +0.059, glt: +0.035, stp: +0.031, unr: +0.030, end: +0.029\n",
      "\n",
      "He went galumphing back.\n",
      "stp: +0.071, vel: +0.071, apr: +0.033, lbv: +0.028, glt: +0.028\n",
      "\n",
      "\"And hast thou slain the Jabberwock?\n",
      "frc: +0.044, vls: +0.043, low: +0.028, dnt: +0.025, alv: +0.023\n",
      "\n",
      "Come to my arms, my beamish boy!\n",
      "blb: +0.122, nas: +0.056, bck: +0.049, smh: +0.041, rnd: +0.032\n",
      "\n",
      "O frabjous day! Callooh! Callay!\"\n",
      "vel: +0.061, stp: +0.039, lat: +0.037, vwl: +0.034, low: +0.033\n",
      "\n",
      "He chortled in his joy.\n",
      "glt: +0.061, smh: +0.052, end: +0.042, alv: +0.030, apr: +0.029\n",
      "\n",
      "'Twas brillig, and the slithy toves\n",
      "alv: +0.054, frc: +0.035, vls: +0.022, vcd: +0.020, lbd: +0.015\n",
      "\n",
      "Did gyre and gimble in the wabe:\n",
      "vcd: +0.093, stp: +0.050, fnt: +0.043, smh: +0.040, unr: +0.029\n",
      "\n",
      "All mimsy were the borogoves,\n",
      "vwl: +0.043, lmd: +0.042, blb: +0.035, lat: +0.030, unr: +0.023\n",
      "\n",
      "And the mome raths outgrabe.\n",
      "nas: +0.039, low: +0.038, rnd: +0.031, bck: +0.027, umd: +0.015\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for line in text.split(\"\\n\"):\n",
    "    # get all words in the line\n",
    "    line_words = [item.lower() for item in re.findall(r\"\\b(\\w+)\\b\", line)]\n",
    "    if len(line_words) == 0:  # skip empty lines\n",
    "        continue\n",
    "    # calculate then normalize phoneme feature probabilities for each word\n",
    "    line_word_feats = np.concatenate([pin.phonemefeatures(word) for word in line_words])\n",
    "    line_word_feats_normal = line_word_feats.sum(axis=0) / line_word_feats.shape[0]\n",
    "    # subtract the average of the entire text\n",
    "    diff = line_word_feats_normal - word_feats_normal\n",
    "    # print line with top five features\n",
    "    out = []\n",
    "    for idx in np.argsort(diff)[::-1][:5]:\n",
    "        out.append(\"%s: %+0.3f\" % (idxfeature(pin, idx), diff[idx]))\n",
    "    print(line.strip())\n",
    "    print(\", \".join(out))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To illustrate how to interpret this output, let's look at the following excerpt:\n",
    "\n",
    "    Come to my arms, my beamish boy!\n",
    "    blb: +0.144, nas: +0.078, smh: +0.077, bck: +0.046, end: +0.029\n",
    "    \n",
    "This tells us that this line has comparatively more bilabial sounds (Co*m*e to *m*y ar*m*s *m*y *b*ea*m*ish *b*oy), nasal sounds (all of the `m`s), semi-high back vowel sounds, and ends of words. Likewise:\n",
    "\n",
    "    One, two! One, two! And through and through\n",
    "    rnd: +0.064, bck: +0.064, alv: +0.051, str: +0.049, nas: +0.046\n",
    "    \n",
    "This shows us that the line has round, back, stressed vowels (i.e., the \"oo\" sounds in \"two\" and \"through\") compared to the rest of the poem. Nice!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Spelling from phoneme features\n",
    "\n",
    "The Pincelate class has another method, `.spellfeatures()`, which works like `.spell()` except it takes an array of phoneme features (such as that returned from `.phonemefeatures()`) instead of a list of Arpabet phonemes. You can use this to re-spell phoneme feature arrays that you have manipulated. In the following cell, I get the phoneme feature probability array for the word `pug`, then overwrite the probability of the \"voiced\" feature for its first phoneme, then respell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bugh'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pug = pin.phonemefeatures(\"pug\")\n",
    "pug[1][pin.featureidx('vcd')] = 1\n",
    "pin.spellfeatures(pug)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or, you can spell from completely random feature probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gyolide\n",
      "houle\n",
      "hcoledhe\n",
      "hyilde\n",
      "hyolde\n",
      "hchaulde\n",
      "guldy\n",
      "horkei\n",
      "hchouldy\n",
      "galedhe\n",
      "ghile\n",
      "gcoledy\n"
     ]
    }
   ],
   "source": [
    "for i in range(12):\n",
    "    print(pin.spellfeatures(np.random.uniform(0, 1, size=(12,32))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "... which (weirdly) seems like someone trying to imitate the sound of white noise.\n",
    "\n",
    "Or, you might want to build up neologism from scratch, specifying their phoneme features by hand. To do this, use Pincelate's `.vectorizefeatures()` method, passing it an array of tuples of phoneme features. It returns a phoneme probability array that you can then send to `.spellfeatures()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bue'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bee = pin.vectorizefeatures([\n",
    "    ['beg'], ['blb', 'stp', 'vcd'], ['hgh', 'fnt', 'vwl'], ['end']\n",
    "])\n",
    "pin.spellfeatures(bee)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As an example, the code in the following cell builds up random five-syllable words from phoneme features (picking places and methods of articulation at random) and spells them out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pubent\n",
      "piegeaun\n",
      "toughtee\n",
      "coughte\n",
      "ducheis\n",
      "kidule\n",
      "giechough\n",
      "kibune\n",
      "dibone\n",
      "guetien\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    feats = [[\"beg\"]]\n",
    "    for j in range(5):\n",
    "        place = random.choice(['blb', 'alv', 'vel'])\n",
    "        voice = random.choice(['vcd', 'vls'])\n",
    "        feats.append([place, voice, 'stp'])\n",
    "        vowel_place = random.choice([[\"fnt\", \"unr\"], [\"bck\", \"rnd\"]])\n",
    "        feats.append(vowel_place + [\"hgh\", \"vwl\"])\n",
    "    feats.append([\"end\"])\n",
    "    word_feats = pin.vectorizefeatures(feats)\n",
    "    print(pin.spellfeatures(word_feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Resizing feature probability arrays\n",
    "\n",
    "Once you have the phonetic feature probability arrays, you can treat them the same way you'd treat any other numpy array. One thing I like to do is use scipy's image manipulation functions and use them resample the phonetic feature arrays. This lets us use the same phonetic information to spell a shorter or longer word. In particular, `scipy.ndimage.interpolation` has a handy [zoom](https://docs.scipy.org/doc/scipy-0.15.1/reference/generated/scipy.ndimage.interpolation.zoom.html) function that resamples an array and interpolates it. Normally you'd use this to resize an image, but nothing's stopping us from using it to resize our phonetic feature array.\n",
    "\n",
    "First, import the function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage.interpolation import zoom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then get some phoneme feature probabilities:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "feats = pin.phonemefeatures(\"alphabet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then resize with `zoom()`. The second parameter to `zoom()` is a tuple with the factor by which to scale the dimensions of the incoming array. We only want to scale along the first axis (i.e., the phonemes), keeping the second axis (i.e., the features) constant.\n",
    "\n",
    "A shorter version of the word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/oryx/anaconda3/envs/pincelate/lib/python3.7/site-packages/scipy/ndimage/interpolation.py:611: UserWarning: From scipy 0.13.0, the output shape of zoom() is calculated with round() instead of int() - for these inputs the size of the returned array has changed.\n",
      "  \"the returned array has changed.\", UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'alse'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shorter = zoom(feats, (0.67, 1))\n",
    "pin.spellfeatures(shorter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A longer version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'alached'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "longer = zoom(feats, (2.0, 1))\n",
    "pin.spellfeatures(longer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've downloaded this notebook and you're following along running the code, the following cell will create an interactive widget that lets you \"stretch\" and \"shrink\" the words that you type into the text box by dragging the slider."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b3509eda22d4669a04002ab9bd9ad64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='how to spell expressively', description='words'), FloatSlider(value=1.0, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "@interact(words=\"how to spell expressively\", factor=(0.1, 4.0, 0.1))\n",
    "def stretchy(words, factor=1.0):\n",
    "    out = []\n",
    "    for word in words.split():\n",
    "        word = word.lower()\n",
    "        vec = pin.phonemefeatures(word)\n",
    "        if factor < 1.0:\n",
    "            order = 3\n",
    "        else:\n",
    "            order = 0\n",
    "        zoomed = zoom(vec, (factor, 1), order=order)\n",
    "        out.append(pin.spellfeatures(zoomed))\n",
    "    print(\" \".join(out))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Round-trip spelling manipulation\n",
    "\n",
    "Pincelate actually consists of *two* models: one that knows how to sound out words based on how they're spelled, , and another that knows how to spell words from sounds. Pincelate's `.manipulate()` function does a \"round trip\" re-spelling of a word, passing it through both models to return back to the original word. Try it out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spenti'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pin.manipulate(\"spelling\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the surface, this isn't very interesting! You don't need Pincelate to tell you how to spell a word that you already know how to spell. But the `.manipulate()` has a handful of parameters that allow you to mess around with the model's internal workings in fun and interesting ways. The first is the `temperature` parameter, which artificially increases or decreases the amount of randomness in the model's output probabilities.\n",
    "\n",
    "### Spelling temperature\n",
    "\n",
    "When the temperature is close to zero, the model will always pick the most likely spelling of the word at each step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spean'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pin.manipulate(\"spelling\", temperature=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you increase the temperature to 1.0, the model starts picking values at random according to the underlying probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spien'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pin.manipulate(\"spelling\", temperature=1.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At temperatures above 1.0, the model has a higher chance of picking from letters with lower probabilities, producing a more unlikely spelling:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spedmje'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pin.manipulate(\"spelling\", temperature=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At a high enough temperature, the model's spelling feels essentially random:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bl.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pin.manipulate(\"spelling\", temperature=3.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following interactive widget lets you play with the `temperature` parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0c99350d13d24ea78635985bf7ab6633",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='your text here', description='s'), FloatSlider(value=1.2500000000000002, des…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(s=\"your text here\", temp=(0.05, 2.5, 0.05))\n",
    "def tempadjust(s, temp):\n",
    "    return ' '.join([pin.manipulate(w.lower(), temperature=temp) for w in s.split()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Manipulating letter frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spani'"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pin.manipulate(\"spelling\", letters={'e': 10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Manipulating sounds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'smange'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pin.manipulate(\"spelling\", features={'nas': -10})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive manipulation tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from ipywidgets import interact, interactive_output, Layout, HBox, VBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def manipulate(instr=\"allison\", temp=0.25, **kwargs):\n",
    "    return ' '.join([\n",
    "        pin.manipulate(\n",
    "            w,\n",
    "            letters={k: v*-1 for k, v in kwargs.items()\n",
    "                  if k in pin.orth2phon.src_vocab_idx_map.keys()},\n",
    "            features={k: v*-1 for k, v in kwargs.items()\n",
    "                      if k in pin.orth2phon.target_vocab_idx_map.keys()},\n",
    "            temperature=temp\n",
    "        ) for w in instr.split()]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "938c843182ed4b2ea9f7c6731b6978bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(VBox(children=(FloatSlider(value=0.0, continuous_update=False, description='$', …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83b090df009d4859abef2a4878bc2bb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output(layout=Layout(height='100px'))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "orth_sliders = {}\n",
    "phon_sliders = {}\n",
    "for ch in pin.orth2phon.src_vocab_idx_map.keys():\n",
    "    if ch in \"'-.\": continue\n",
    "    orth_sliders[ch] = widgets.FloatSlider(description=ch,\n",
    "                               continuous_update=False,\n",
    "                               value=0,\n",
    "                               min=-20,\n",
    "                               max=20,\n",
    "                               step=0.5,\n",
    "                               layout=Layout(height=\"10px\"))\n",
    "for feat in pin.orth2phon.target_vocab_idx_map.keys():\n",
    "    if feat in (\"beg\", \"end\", \"cnt\", \"dnt\"): continue\n",
    "    phon_sliders[feat] = widgets.FloatSlider(description=feat,\n",
    "                               continuous_update=False,\n",
    "                               value=0,\n",
    "                               min=-20,\n",
    "                               max=20,\n",
    "                               step=0.5,\n",
    "                               layout=Layout(height=\"10px\"))\n",
    "instr = widgets.Text(description='input', value=\"spelling words with machine learning\")\n",
    "tempslider = widgets.FloatSlider(description='temp', continuous_update=False, value=0.3, min=0.01, max=5, step=0.05)\n",
    "left_box = VBox(tuple(orth_sliders.values()) + (tempslider,))\n",
    "right_box = VBox(tuple(phon_sliders.values()))\n",
    "all_sliders = HBox([left_box, right_box])\n",
    "\n",
    "out = interactive_output(lambda *args, **kwargs: print(manipulate(*args, **kwargs)),\n",
    "                         dict(instr=instr, temp=tempslider, **orth_sliders, **phon_sliders))\n",
    "out.layout.height = \"100px\"\n",
    "display(VBox([all_sliders, instr]), out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Phonetic states"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Homotopies (blending words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = [('paper', 'plastic'),\n",
    "         ('kitten', 'puppy'),\n",
    "         ('birthday', 'anniversary'),\n",
    "         ('artificial', 'intelligence'),\n",
    "         ('allison', 'parrish'),\n",
    "         ('moses', 'middletown'),\n",
    "         ('day', 'night'),\n",
    "         ('january', 'december')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "peter → prace → place\n",
      "kiter → coter → putie\n",
      "birse → ancher → ansear\n",
      "archain → ancher → inties\n",
      "allis → allis → paris\n",
      "mossear → mossear → mitson\n",
      "dais → dean → nite\n",
      "janes → deasse → desmar\n"
     ]
    }
   ],
   "source": [
    "for start_s, end_s in pairs:\n",
    "    start = pin.phonemestate(start_s)\n",
    "    end = pin.phonemestate(end_s)\n",
    "    steps = 2\n",
    "    out = []\n",
    "    for i in range(steps+1):\n",
    "        out.append(\n",
    "            pin.spellstate(\n",
    "                (start*(1-(i/steps))) + (end*(i/steps))\n",
    "            )\n",
    "        )\n",
    "    print(\" → \".join(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'o2ps_tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-57-dbcd0b5651ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m centroid = (o2ps_tr.translate(\"wordhack\") + \\\n\u001b[0;32m----> 2\u001b[0;31m            \u001b[0mo2ps_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"open\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m            o2ps_tr.translate(\"projector\")) / 3\n",
      "\u001b[0;31mNameError\u001b[0m: name 'o2ps_tr' is not defined"
     ]
    }
   ],
   "source": [
    "centroid = (o2ps_tr.translate(\"wordhack\") + \\\n",
    "           o2ps_tr.translate(\"open\") + \\\n",
    "           o2ps_tr.translate(\"projector\")) / 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ps2o_tr' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-58-2b053d74f0ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mps2o_tr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranslate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcentroid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.55\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'ps2o_tr' is not defined"
     ]
    }
   ],
   "source": [
    "ps2o_tr.translate(centroid, temp=0.55)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Phonetic resizing of texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "094eb934f2e040ed87c8488493260346",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Text(value='your text here', description='s'), FloatSlider(value=1.0, description='facto…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "@interact(s=\"your text here\", factor=(0.00, 4, 0.1), continuous_update=False)\n",
    "def resizer(s, factor=1.0):\n",
    "    orig = np.array(\n",
    "        [pin.phonemestate(tok.lower()) for tok in s.split()]\n",
    "    )\n",
    "    resized = zoom(orig, (factor, 1), order=4)\n",
    "    return \" \".join([pin.spellstate(vec) for vec in resized])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: Phonetic similarity with phoneme states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity(s1, s2):\n",
    "    return 1 - cosine(pin.phonemestate(s1), pin.phonemestate(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.706063449382782"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(\"hello\", \"bellow\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7466654181480408"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(\"kiki\", \"bouba\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9869937896728516"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(\"righter\", \"writer\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.974277138710022"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(\"this\", \"that\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8288887143135071"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(\"moop\", \"poom\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8154409527778625"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(\"lipstick\", \"plastic\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7981315851211548"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity(\"lipstick\", \"mascara\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
